#!/usr/bin/env python3
"""
Airgarage Phase 9 (Final): Global Variance & Max-Cut Partitioning
Strategy:
1. "Prove it moves": Calculates Standard Deviation of the group's visuals.
   - If Low Variance -> TRASH IT (Static car, waiting in line).
2. "Max-Cut": Finds the single largest visual jump in the timeline.
3. "One Strong Pair": Extracts only the single best In/Out pair across that jump.
Result: Eliminates the ~7,000 False Positive pairs generated by static cars.
"""

import os
import sys
import json
import numpy as np
from tqdm import tqdm

# ============= CONFIG =============
SOURCE_TEXT_FILE = "vehicle_images_input_part2 (4).txt" 
INPUT_METADATA = "vehicle_metadata.json"
OUTPUT_PAIRS = "variance_filtered_pairs.txt"

# 1. VARIANCE FILTER
# If the StdDev of Color < 0.05, the car basically didn't change color/lighting.
# We drop these groups entirely.
MIN_GROUP_VARIANCE = 0.05 

# 2. CUT THRESHOLD
# The visual jump between 'In' and 'Out' must be at least 25%.
MIN_CUT_SEVERITY = 0.25
# ==================================

def get_vectors(entries):
    """
    Converts a list of entries into a numpy array of visual vectors.
    """
    vecs = []
    for e in entries:
        if 'meta' in e and e['meta']:
            rgb = e['meta'].get('avg_color_rgb', [0,0,0])
            # Normalize to 0-1
            v = [rgb[0]/255.0, rgb[1]/255.0, rgb[2]/255.0]
            vecs.append(v)
        else:
            vecs.append([0,0,0])
    return np.array(vecs)

class VarianceSplitter:
    def __init__(self):
        self.url_map = {}
        self.stats = {
            "total_groups": 0,
            "dropped_static": 0,
            "dropped_weak_cut": 0,
            "pairs_saved": 0
        }

    def load_timeline(self):
        print(f"[INIT] Mapping timeline from {SOURCE_TEXT_FILE}...")
        if not os.path.exists(SOURCE_TEXT_FILE):
            print("âŒ Source file missing.")
            sys.exit(1)
        with open(SOURCE_TEXT_FILE, 'r') as f:
            for idx, line in enumerate(f):
                self.url_map[line.strip()] = idx

    def get_best(self, entries):
        """Returns image with highest confidence."""
        if not entries: return None
        entries.sort(key=lambda x: x.get('conf', 0), reverse=True)
        return entries[0]

    def process_group(self, entries):
        # 1. Sort by Time
        entries.sort(key=lambda x: x.get('line_idx', 999999))
        
        # 2. Global Variance Check (The "Static Filter")
        vectors = get_vectors(entries)
        if len(vectors) < 2: return None
        
        # Calculate standard deviation of the color channels
        std_devs = np.std(vectors, axis=0) # [std_R, std_G, std_B]
        avg_std = np.mean(std_devs)
        
        if avg_std < MIN_GROUP_VARIANCE:
            # The images are too similar globally. It's a static event.
            self.stats['dropped_static'] += 1
            return None

        # 3. Find Max-Cut (The biggest jump between adjacent frames)
        max_diff = 0.0
        cut_index = -1
        
        for i in range(len(vectors) - 1):
            # Euclidean distance between Frame i and Frame i+1
            diff = np.linalg.norm(vectors[i] - vectors[i+1])
            # Normalize (Max dist is sqrt(3) ~ 1.73)
            diff /= 1.73
            
            if diff > max_diff:
                max_diff = diff
                cut_index = i
        
        # 4. Validate Cut
        if max_diff < MIN_CUT_SEVERITY:
            # Even the biggest jump wasn't big enough (Gradual change?)
            self.stats['dropped_weak_cut'] += 1
            return None

        # 5. Extract One Strong Pair
        # Group A: 0 .. cut_index
        # Group B: cut_index+1 .. end
        group_a = entries[:cut_index+1]
        group_b = entries[cut_index+1:]
        
        best_a = self.get_best(group_a)
        best_b = self.get_best(group_b)
        
        if best_a and best_b:
            self.stats['pairs_saved'] += 1
            return (best_a, best_b)
            
        return None

    def run(self):
        self.load_timeline()
        
        print(f"[LOAD] Reading Metadata...")
        with open(INPUT_METADATA, 'r') as f:
            data = json.load(f)

        valid_data = []
        for x in data:
            u = x.get('url', '').strip()
            if u in self.url_map:
                x['line_idx'] = self.url_map[u]
            valid_data.append(x)

        groups = {}
        for x in valid_data:
            p = x.get('plate')
            if p: 
                if p not in groups: groups[p] = []
                groups[p].append(x)

        print(f"[RUN] Analyzing {len(groups)} plates...")
        
        all_pairs = []
        for plate, entries in tqdm(groups.items()):
            # Run on everything with >= 2 images
            if len(entries) < 2: continue
            self.stats['total_groups'] += 1
            
            pair = self.process_group(entries)
            if pair:
                all_pairs.append(pair)

        print(f"[SAVE] Writing {len(all_pairs)} pairs...")
        with open(OUTPUT_PAIRS, 'w') as f:
            for p1, p2 in all_pairs:
                f.write(f"{p1['url']},{p2['url']}\n")

        print("="*40)
        print(f"âœ… VARIANCE SPLITTING COMPLETE")
        print(f"ðŸ”¹ Total Groups:     {self.stats['total_groups']}")
        print(f"âŒ Dropped (Static): {self.stats['dropped_static']}")
        print(f"âŒ Dropped (Weak):   {self.stats['dropped_weak_cut']}")
        print(f"âœ… Final Pairs:      {self.stats['pairs_saved']}")
        print("="*40)

if __name__ == "__main__":
    vs = VarianceSplitter()
    vs.run()